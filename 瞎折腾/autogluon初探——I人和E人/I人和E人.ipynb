{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cf0df5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huangzy/miniconda3/envs/ag/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5815e5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250801_124140\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.11.13\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #63~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Apr 22 19:00:15 UTC 2\n",
      "CPU Count:          128\n",
      "Memory Avail:       350.05 GB / 503.51 GB (69.5%)\n",
      "Disk Space Avail:   2776.85 GB / 4764.37 GB (58.3%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme' : New in v1.4: Massively better than 'best' on datasets <30000 samples by using new models meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, and TabM. Absolute best accuracy. Requires a GPU. Recommended 64 GB CPU memory and 32+ GB GPU memory.\n",
      "\tpresets='best'    : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'    : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'    : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'  : Fast training time, ideal for initial prototyping.\n",
      "Using hyperparameters preset: hyperparameters='default'\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/huangzy/learning/瞎折腾/kaggle/AutogluonModels/ag-20250801_124140\"\n",
      "Train Data Rows:    18524\n",
      "Train Data Columns: 7\n",
      "Label Column:       Personality\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  ['Extrovert', 'Introvert']\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = Introvert, class 0 = Extrovert\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Introvert) vs negative (Extrovert) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    358465.89 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.72 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 5 | ['Time_spent_Alone', 'Social_event_attendance', 'Going_outside', 'Friends_circle_size', 'Post_frequency']\n",
      "\t\t('object', []) : 2 | ['Stage_fear', 'Drained_after_socializing']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 2 | ['Stage_fear', 'Drained_after_socializing']\n",
      "\t\t('float', [])    : 5 | ['Time_spent_Alone', 'Social_event_attendance', 'Going_outside', 'Friends_circle_size', 'Post_frequency']\n",
      "\t0.1s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.74 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.1s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 16671, Val Rows: 1853\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT ...\n",
      "\tFitting with cpus=64, gpus=0, mem=0.0/350.0 GB\n",
      "\t0.9703\t = Validation score   (accuracy)\n",
      "\t0.62s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\tFitting with cpus=64, gpus=0, mem=0.0/350.0 GB\n",
      "\t0.9692\t = Validation score   (accuracy)\n",
      "\t0.57s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\tFitting with cpus=128, gpus=0, mem=0.0/350.0 GB\n",
      "\t0.9638\t = Validation score   (accuracy)\n",
      "\t1.96s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\tFitting with cpus=128, gpus=0, mem=0.0/349.7 GB\n",
      "\t0.9633\t = Validation score   (accuracy)\n",
      "\t1.71s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\tFitting with cpus=64, gpus=0\n",
      "\t0.9698\t = Validation score   (accuracy)\n",
      "\t1.38s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\tFitting with cpus=128, gpus=0, mem=0.0/349.5 GB\n",
      "\t0.9633\t = Validation score   (accuracy)\n",
      "\t1.68s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\tFitting with cpus=128, gpus=0, mem=0.0/348.1 GB\n",
      "\t0.9644\t = Validation score   (accuracy)\n",
      "\t2.09s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\tFitting with cpus=64, gpus=0, mem=0.0/347.9 GB\n",
      "\t0.9709\t = Validation score   (accuracy)\n",
      "\t16.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\tFitting with cpus=64, gpus=0\n",
      "\t0.9692\t = Validation score   (accuracy)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\tFitting with cpus=64, gpus=0, mem=0.0/349.1 GB\n",
      "/home/huangzy/miniconda3/envs/ag/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\t0.9703\t = Validation score   (accuracy)\n",
      "\t8.93s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\tFitting with cpus=64, gpus=0, mem=0.0/349.1 GB\n",
      "\t0.9687\t = Validation score   (accuracy)\n",
      "\t2.17s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'NeuralNetFastAI': 1.0}\n",
      "\t0.9709\t = Validation score   (accuracy)\n",
      "\t0.08s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 39.21s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 80033.4 rows/s (1853 batch size)\n",
      "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (1853 rows).\n",
      "\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/huangzy/learning/瞎折腾/kaggle/AutogluonModels/ag-20250801_124140\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np  \n",
    "# 1. 读取数据\n",
    "data_path = '/home/huangzy/learning/瞎折腾/kaggle/datas/i人和e人/train.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "# 删除id列\n",
    "df.drop(columns=['id'], inplace=True)\n",
    "\n",
    "train_data = df.copy()\n",
    "\n",
    "predictor = TabularPredictor(label='Personality').fit(train_data)\n",
    "# 2. 预测\n",
    "test_data = pd.read_csv('/home/huangzy/learning/瞎折腾/kaggle/datas/i人和e人/test.csv')\n",
    "test_data.drop(columns=['id'], inplace=True)\n",
    "predictions = predictor.predict(test_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb49ddf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "提交文件预览:\n",
      "      id Personality\n",
      "0  18524   Extrovert\n",
      "1  18525   Introvert\n",
      "2  18526   Extrovert\n",
      "3  18527   Extrovert\n",
      "4  18528   Introvert\n",
      "\n",
      "提交文件形状: (6175, 2)\n",
      "预测结果分布:\n",
      "Personality\n",
      "Extrovert    4619\n",
      "Introvert    1556\n",
      "Name: count, dtype: int64\n",
      "\n",
      "提交文件已保存到: /home/huangzy/learning/瞎折腾/kaggle/datas/i人和e人/submission.csv\n",
      "\n",
      "验证提交文件:\n",
      "列名: ['id', 'Personality']\n",
      "文件大小: (6175, 2)\n",
      "前5行预览:\n",
      "      id Personality\n",
      "0  18524   Extrovert\n",
      "1  18525   Introvert\n",
      "2  18526   Extrovert\n",
      "3  18527   Extrovert\n",
      "4  18528   Introvert\n"
     ]
    }
   ],
   "source": [
    "# 3. 准备提交文件（Kaggle格式）\n",
    "# 读取原始测试数据以获取ID\n",
    "test_data_with_id = pd.read_csv('/home/huangzy/learning/瞎折腾/kaggle/datas/i人和e人/test.csv')\n",
    "\n",
    "# 创建提交DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_data_with_id['id'],  # 保留原始ID\n",
    "    'Personality': predictions  # 预测结果\n",
    "})\n",
    "\n",
    "print(\"提交文件预览:\")\n",
    "print(submission.head())\n",
    "print(f\"\\n提交文件形状: {submission.shape}\")\n",
    "print(f\"预测结果分布:\")\n",
    "print(submission['Personality'].value_counts())\n",
    "\n",
    "# 保存为CSV文件\n",
    "submission_path = '/home/huangzy/learning/瞎折腾/kaggle/datas/i人和e人/submission.csv'\n",
    "submission.to_csv(submission_path, index=False)\n",
    "print(f\"\\n提交文件已保存到: {submission_path}\")\n",
    "\n",
    "# 验证文件格式\n",
    "print(f\"\\n验证提交文件:\")\n",
    "saved_submission = pd.read_csv(submission_path)\n",
    "print(f\"列名: {saved_submission.columns.tolist()}\")\n",
    "print(f\"文件大小: {saved_submission.shape}\")\n",
    "print(\"前5行预览:\")\n",
    "print(saved_submission.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
