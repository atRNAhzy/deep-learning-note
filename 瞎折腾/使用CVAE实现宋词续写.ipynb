{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "428a0e1a",
   "metadata": {},
   "source": [
    "# 使用CVAE实现宋词续写"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff2f8b9",
   "metadata": {},
   "source": [
    "数据集: [chinese-poetry/chinese-poetry: The most comprehensive database of Chinese poetry ](https://github.com/chinese-poetry/chinese-poetry)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ee5afc",
   "metadata": {},
   "source": [
    "> 为什么会有这个项目：  \n",
    "> 花了很长时间终于彻底理解了ACT的模型部分，正好又看到苏剑林大佬写的VAE文章，讲得非常透彻，让我信心大增，想试着整点活。最近事情也告一段落，于是趁机摸鱼。这个项目花了三个多小时写完，改了几次模型结构但是基本没调参。最后让AI帮忙优化了一下代码（要优雅！！），纯属娱乐，不要太在意效果（"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b6ffb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec1d355",
   "metadata": {},
   "source": [
    "## 1. 数据加载与预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b509cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1000 items from ci.song.15000.json\n",
      "Loaded 2000 items from ci.song.7000.json\n",
      "Loaded 3000 items from ci.song.3000.json\n",
      "Loaded 4000 items from ci.song.11000.json\n",
      "Loaded 4050 items from ci.song.21000.json\n",
      "Loaded 5050 items from ci.song.2000.json\n",
      "Loaded 6050 items from ci.song.17000.json\n",
      "Loaded 7050 items from ci.song.16000.json\n",
      "Loaded 8050 items from ci.song.18000.json\n",
      "Loaded 9050 items from ci.song.10000.json\n",
      "Loaded 10050 items from ci.song.6000.json\n",
      "Loaded 11050 items from ci.song.19000.json\n",
      "Loaded 12050 items from ci.song.8000.json\n",
      "Loaded 13050 items from ci.song.9000.json\n",
      "Loaded 14050 items from ci.song.4000.json\n",
      "Loaded 15050 items from ci.song.20000.json\n",
      "Loaded 16050 items from ci.song.0.json\n",
      "Loaded 17050 items from ci.song.13000.json\n",
      "Loaded 18050 items from ci.song.12000.json\n",
      "Loaded 19050 items from ci.song.5000.json\n",
      "Loaded 19053 items from ci.song.2019y.json\n",
      "Loaded 20053 items from ci.song.14000.json\n",
      "Loaded 21053 items from ci.song.1000.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 假设数据格式为 [{\"rhythmic\": \"水调歌头\", \"lines\": [\"明月几时有\", \"把酒问青天\", ...]}, ...]\n",
    "# 读取所有ci.song开头的json文件\n",
    "data_dir = './datas/宋词'  # 修改为你的数据文件夹路径\n",
    "all_data = []\n",
    "for fname in os.listdir(data_dir):\n",
    "    if fname.startswith('ci.song') and fname.endswith('.json'):\n",
    "        with open(os.path.join(data_dir, fname), encoding='utf-8') as f:\n",
    "            all_data.extend(json.load(f))\n",
    "            print(f\"Loaded {len(all_data)} items from {fname}\")\n",
    "\n",
    "# 构建词表\n",
    "lines = []\n",
    "rhythmic = set()\n",
    "for item in all_data:\n",
    "    rhythmic.add(item['rhythmic'])\n",
    "    for i in range(len(item['paragraphs']) - 1):\n",
    "        lines.append((item['rhythmic'], item['paragraphs'][i], item['paragraphs'][i+1]))\n",
    "\n",
    "# 字符级tokenizer\n",
    "from collections import Counter\n",
    "all_text = ''.join([l[1]+l[2] for l in lines])\n",
    "char_count = Counter(all_text)\n",
    "chars = ['<PAD>', '<BOS>', '<EOS>', '<UNK>'] + [c for c, _ in char_count.most_common()]\n",
    "char2idx = {c: i for i, c in enumerate(chars)}\n",
    "idx2char = {i: c for c, i in char2idx.items()}\n",
    "\n",
    "# 词牌名编码\n",
    "rhythmic2idx = {c: i for i, c in enumerate(sorted(list(rhythmic)))}\n",
    "idx2rhythmic = {i: c for c, i in rhythmic2idx.items()}\n",
    "\n",
    "def encode_line(line, max_len):\n",
    "    ids = [char2idx.get('<BOS>')]\n",
    "    for c in line:\n",
    "        ids.append(char2idx.get(c, char2idx['<UNK>']))\n",
    "    ids.append(char2idx.get('<EOS>'))\n",
    "    if len(ids) < max_len:\n",
    "        ids += [char2idx['<PAD>']] * (max_len - len(ids))\n",
    "    else:\n",
    "        ids = ids[:max_len]\n",
    "    return ids\n",
    "\n",
    "max_len = max(max(len(l[1]), len(l[2])) for l in lines) + 2  # +2 for BOS/EOS\n",
    "\n",
    "class SongLineDataset(Dataset):\n",
    "    def __init__(self, lines):\n",
    "        self.data = lines\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        rhythmic, prev, next_ = self.data[idx]\n",
    "        return (\n",
    "            rhythmic2idx[rhythmic],\n",
    "            torch.tensor(encode_line(prev, max_len)),\n",
    "            torch.tensor(encode_line(next_, max_len))\n",
    "        )\n",
    "\n",
    "dataset = SongLineDataset(lines)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c59161",
   "metadata": {},
   "source": [
    "## 2. CVAE模型定义\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f9f052e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, rhythmic_size, emb_dim, cond_dim, hidden_dim, latent_dim):\n",
    "        super().__init__()\n",
    "        self.char_emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.rhythmic_emb = nn.Embedding(rhythmic_size, cond_dim)\n",
    "        self.rnn = nn.GRU(emb_dim + cond_dim, hidden_dim, batch_first=True)\n",
    "        self.linear_mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.linear_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "\n",
    "    def forward(self, x, rhythmic):\n",
    "        x_emb = self.char_emb(x)\n",
    "        rhythmic_emb = self.rhythmic_emb(rhythmic).unsqueeze(1).expand(-1, x.size(1), -1)\n",
    "        inp = torch.cat([x_emb, rhythmic_emb], dim=-1)\n",
    "        _, h = self.rnn(inp)\n",
    "        h = h.squeeze(0)\n",
    "        mu = self.linear_mu(h)\n",
    "        logvar = self.linear_logvar(h)\n",
    "        return mu, logvar\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, rhythmic_size, emb_dim, cond_dim, latent_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.char_emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.rhythmic_emb = nn.Embedding(rhythmic_size, cond_dim)\n",
    "        self.latent2hidden = nn.Linear(latent_dim + cond_dim, hidden_dim)\n",
    "        self.rnn = nn.GRU(emb_dim + cond_dim, hidden_dim, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x, z, rhythmic):\n",
    "        rhythmic_emb = self.rhythmic_emb(rhythmic)\n",
    "        zc = torch.cat([z, rhythmic_emb], dim=-1)\n",
    "        h0 = self.latent2hidden(zc).unsqueeze(0)\n",
    "        x_emb = self.char_emb(x)\n",
    "        rhythmic_emb_seq = rhythmic_emb.unsqueeze(1).expand(-1, x.size(1), -1)\n",
    "        inp = torch.cat([x_emb, rhythmic_emb_seq], dim=-1)\n",
    "        out, _ = self.rnn(inp, h0)\n",
    "        logits = self.out(out)\n",
    "        return logits\n",
    "\n",
    "class CVAE(nn.Module):\n",
    "    def __init__(self, vocab_size, rhythmic_size, emb_dim=128, cond_dim=32, hidden_dim=256, latent_dim=64):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(vocab_size, rhythmic_size, emb_dim, cond_dim, hidden_dim, latent_dim)\n",
    "        self.decoder = Decoder(vocab_size, rhythmic_size, emb_dim, cond_dim, latent_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, prev_line, next_line, rhythmic):\n",
    "        mu, logvar = self.encoder(prev_line, rhythmic)\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        z = mu + eps * std\n",
    "        logits = self.decoder(next_line[:, :-1], z, rhythmic)\n",
    "        return logits, mu, logvar\n",
    "\n",
    "    def generate(self, prev_line, rhythmic, max_len=20, device='cpu'):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            mu, logvar = self.encoder(prev_line, rhythmic)\n",
    "            z = mu  # 使用均值\n",
    "            input_seq = torch.tensor([[char2idx['<BOS>']]] * prev_line.size(0), device=device)\n",
    "            outputs = []\n",
    "            h = None\n",
    "            for _ in range(max_len):\n",
    "                logits = self.decoder(input_seq, z, rhythmic)\n",
    "                next_token = logits[:, -1, :].argmax(-1, keepdim=True)\n",
    "                outputs.append(next_token)\n",
    "                input_seq = torch.cat([input_seq, next_token], dim=1)\n",
    "                if (next_token == char2idx['<EOS>']).all():\n",
    "                    break\n",
    "            outputs = torch.cat(outputs, dim=1)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33f3bb2",
   "metadata": {},
   "source": [
    "## 3. 模型训练与推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d221f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = CVAE(len(char2idx), len(rhythmic2idx)).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=char2idx['<PAD>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "675a6358",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_line(ids):\n",
    "    chars_ = []\n",
    "    for i in ids:\n",
    "        c = idx2char.get(i, '')\n",
    "        if c == '<EOS>':\n",
    "            break\n",
    "        if c not in ['<PAD>', '<BOS>', '<EOS>']:\n",
    "            chars_.append(c)\n",
    "    return ''.join(chars_)\n",
    "\n",
    "def predict_next_line(prev_line, rhythmic_name):\n",
    "    model.eval()\n",
    "    prev_ids = torch.tensor([encode_line(prev_line, max_len)], device=device)\n",
    "    rhythmic_id = torch.tensor([rhythmic2idx[rhythmic_name]], device=device)\n",
    "    out_ids = model.generate(prev_ids, rhythmic_id, max_len=max_len, device=device)\n",
    "    return decode_line(out_ids[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63799594",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2157/2157 [00:45<00:00, 47.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 5.0727\n",
      "明月几时有 (水调歌头) → 一笑一枝，一笑一枝春色，不见不知春。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2157/2157 [00:44<00:00, 48.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 4.3998\n",
      "明月几时有 (水调歌头) → 一笑一枝头，看取次，一杯酒，一杯酒。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2157/2157 [00:44<00:00, 48.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 4.1749\n",
      "明月几时有 (水调歌头) → 一笑一生一，一笑付与君。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2157/2157 [00:44<00:00, 47.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 4.0416\n",
      "明月几时有 (水调歌头) → 一杯酒，一笑一，一杯酒。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2157/2157 [00:44<00:00, 47.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 3.9461\n",
      "明月几时有 (水调歌头) → 天际水云乡。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2157/2157 [00:44<00:00, 47.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 3.8729\n",
      "明月几时有 (水调歌头) → 不用登临临水，不用登临赋酒，不用写长安。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2157/2157 [00:44<00:00, 48.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 3.8148\n",
      "明月几时有 (水调歌头) → 一笑天然无处，不见龙山飞舞，一笑俯天潢。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2157/2157 [00:44<00:00, 48.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 3.7657\n",
      "明月几时有 (水调歌头) → 不知何处，有人知我亦何忧。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2157/2157 [00:44<00:00, 48.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 3.7241\n",
      "明月几时有 (水调歌头) → 一笑嫣然一笑，不肯放春风力，不用污人愁。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2157/2157 [00:44<00:00, 48.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 3.6874\n",
      "明月几时有 (水调歌头) → 一笑平生志，非雾非烟非。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def kl_loss(mu, logvar):\n",
    "    return -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1).mean()\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for rhythmic, prev, next_ in tqdm(dataloader):\n",
    "        rhythmic = rhythmic.to(device)\n",
    "        prev = prev.to(device)\n",
    "        next_ = next_.to(device)\n",
    "        logits, mu, logvar = model(prev, next_, rhythmic)\n",
    "        loss_rec = loss_fn(logits.reshape(-1, logits.size(-1)), next_[:,1:].reshape(-1))\n",
    "        loss_kl = kl_loss(mu, logvar)\n",
    "        loss = loss_rec + 0.1 * loss_kl\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(dataloader):.4f}\")\n",
    "    print(f\"明月几时有 (水调歌头) → {predict_next_line('明月几时有', '水调歌头')}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e84d8f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "明月几时有 (水调歌头) → 一笑平生志，非雾非烟非。\n",
      "了却君王天下事 (破阵子) → 一曲清歌，一声声断云。\n",
      "稻花香里说丰年 (西江月) → 不道春工不管。\n",
      "众里寻他千百度 (青玉案) → 一年一度春风雨。\n",
      "江晚正愁余 (菩萨蛮) → 一枝春色生春色。\n",
      "我想下班 (水调歌头) → 一笑平生志，非雾非烟非。\n",
      "怎么还有一个小时才下班 (破阵子) → 一曲清歌，一声声断云。\n",
      "怎么还有三天才周末 (西江月) → 不道春工不管。\n",
      "原来周二才是最难熬的 (青玉案) → 一年一度春风雨。\n"
     ]
    }
   ],
   "source": [
    "tests = [\n",
    "    ('明月几时有', '水调歌头'),\n",
    "    ('了却君王天下事', '破阵子'),\n",
    "    ('稻花香里说丰年', '西江月'),\n",
    "    ('众里寻他千百度', '青玉案'),\n",
    "    ('江晚正愁余', '菩萨蛮'),\n",
    "    ('我想下班', '水调歌头'),\n",
    "    ('怎么还有一个小时才下班', '破阵子'),\n",
    "    ('怎么还有三天才周末', '西江月'),\n",
    "    ('原来周二才是最难熬的', '青玉案')]\n",
    "\n",
    "\n",
    "for prev_line, rhythmic_name in tests:\n",
    "    print(f\"{prev_line} ({rhythmic_name}) → {predict_next_line(prev_line, rhythmic_name)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uplc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
